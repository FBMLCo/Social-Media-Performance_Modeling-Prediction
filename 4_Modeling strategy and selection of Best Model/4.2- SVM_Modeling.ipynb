{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4.2: Modeling Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the methodology\n",
    "> * Finalize bining of Target Variable\n",
    "* Create Train and Test datasets\n",
    "* Rationale about the types of SVM Kernel selected\n",
    "* Create a SVM pipeline(s)\n",
    "* Define key parameters\n",
    "* Run the model(s) on sub-train data set and test accuracy on the validation data set\n",
    "* Select 2 most accurate models based on the hyper-parameters, run it to get the confusion matrix\n",
    "* Evaluate impact of cross-validation if we would see some overfitting with the standard train/valid approach\n",
    "* Select Best SVM model candidate and apply it to a larger train/test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.fftpack as sp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import os\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from scipy.linalg import lstsq # multiple linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "import scikitplot as skplt\n",
    "\n",
    "import random\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "# Activate Seaborn style\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the file for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the file and creating a dataframe\n",
    "master_modeling=pd.read_csv(\"master_modeling.csv\",low_memory=False, skipinitialspace=True)#, sep='\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194484, 351)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the Unnamed column\n",
    "master_modeling.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "master_modeling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the modeling phase (without text and not relevant features)\n",
    "df_modeling=master_modeling.drop(['Title', 'Post_ID','Snippet'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194484, 348)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of # of classes for the Target Variable 'All_Impact'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * We will split the variable in 3 classes using Scikit Learn preprocessing function KBinDiscretizer with the following parameters: number of bins 3, encode: ordinal and strategy: quantile\n",
    "* Oridinal has been selected as we are trying to model a hierarchy between low and high tweet impact\n",
    "* Quantile implies an even number of data points per class which would shape the model to learn about features for each class equally (avoiding unbalance classes)\n",
    "* We may reconsider some of the value of the parameters depending on the modeling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_bin=master_modeling[['ALL_Impact']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process binizer\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "est.fit(ai_bin)\n",
    "new_ai = est.transform(ai_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., 30., 41., 80.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the edge of the different 3 bins\n",
    "est.bin_edges_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ai_df=pd.DataFrame(new_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194484, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ai_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling['All_impact bin']=new_ai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    69658\n",
       "1.0    63049\n",
       "0.0    61777\n",
       "Name: All_impact bin, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling['All_impact bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    2.0\n",
       "4    2.0\n",
       "Name: All_impact bin, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling['All_impact bin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the original All_Impact feature\n",
    "df_modeling2=df_modeling.drop(['ALL_Impact','TW_Hashtags','ALL_Author','TW_Account_Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform new All Impact feature type into int64\n",
    "df_modeling2['All_impact bin']=df_modeling2['All_impact bin'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194484, 345)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a train, validation and test datasets (from the main Train set of data)\n",
    "> * I am facing a lack of computing resources (laptop with i7 Intel chip and 16 Go RAM, no GPU) which implies a very long time for training models, especially with the tuning of hyper-parameters. As a consequence, I have combined my computing resources with Google Colaboratory in order to tune several parameters in parallel.\n",
    "* **The overall dataset is divided in 3 buckets:**\n",
    "* Bucket 1 (train/test): split for training the Best Selected model (in case of more important computing resources)\n",
    "* Bucket 2 (train1/valid1): split for training the Best model candidate of a given class (no cross-validation)\n",
    "* Bucket 3 (train2/valid2): split for hyper-parameter tuning leading to select the Best model candidate (cross-validation maybe considered in some cases)\n",
    "* We could limit the risk of overfitting by using a cross-validation approach. However, we may run the risk of very demanding computing resources as we will combine hyper-parameter optimization (GridSearch) and large dataset (194484 rows x 344 variables).\n",
    "* A compromised approach would be to use the standard train/test dataset split and leverage cross-validation for the validation phase in the process for selecting the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194484, 344)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an array from df_modeling2 excluding the target variable All impact bin\n",
    "X=df_modeling2.drop(['All_impact bin'], axis=1)\n",
    "# X=np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194484,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create y array for the target variable All impact bin\n",
    "y=df_modeling2['All_impact bin']\n",
    "# y=np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (155587, 344) (155587,)\n",
      "Test: (38897, 344) (38897,)\n",
      "Train1: (60000, 344) (60000,)\n",
      "Valid1: (20000, 344) (20000,)\n",
      "Train2: (5000, 344) (5000,)\n",
      "Valid2: (1500, 344) (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the type of the input matrix to float\n",
    "X = X.astype(np.float)\n",
    "\n",
    "# Create train set\n",
    "X_tr_main, X_test, y_tr_main, y_test = train_test_split(X,\n",
    "    y,\n",
    "    test_size=0.2, random_state=0)\n",
    "\n",
    "# Create validation and test sets for best model selected for a given class\n",
    "X_tr_2nd, X_valid1, y_tr_2nd, y_valid1 = train_test_split(\n",
    "    X_tr_main, y_tr_main, test_size=20000, train_size = 60000, random_state=0)\n",
    "\n",
    "# Create validation and test sets for hyper-parameter tuning and selection of the best model candidate\n",
    "X_tr_3rd, X_valid2, y_tr_3rd, y_valid2 = train_test_split(\n",
    "    X_tr_2nd, y_tr_2nd, test_size=1500, train_size = 5000, random_state=0)\n",
    "\n",
    "print('Train:', X_tr_main.shape, y_tr_main.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)\n",
    "print('Train1:', X_tr_2nd.shape, y_tr_2nd.shape)\n",
    "print('Valid1:', X_valid1.shape, y_valid1.shape)\n",
    "print('Train2:', X_tr_3rd.shape, y_tr_3rd.shape)\n",
    "print('Valid2:', X_valid2.shape, y_valid2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.368667\n",
       "1    0.318000\n",
       "0    0.313333\n",
       "Name: All_impact bin, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_valid2, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single file with X_tr_2nd and y_tr_2nd Train dataframe (features and target variables) which will be used for the final evaluation on the Master Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 344)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_2nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_2nd=pd.DataFrame(y_tr_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_impact bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19131</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40331</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31775</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93271</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        All_impact bin\n",
       "19131                2\n",
       "40331                0\n",
       "31775                1\n",
       "167278               0\n",
       "93271                1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_2nd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge X and y variable in one dataframe\n",
    "svm_train_60k=pd.merge(X_tr_2nd,y_tr_2nd, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_train_60k.to_csv('svm_train_60k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale about the types of SVM Kernel selected\n",
    "> *  We will perform first a SVC with linear kernel tuning C which will set a baseline. We will move to SVC with RBF kernel optimizing C and Gamma.\n",
    "* This approach will hepl to understand the pertinence of a linear approach vs non-linear, especially as we are dealing with transformed text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create a SVM with Linear Kernel pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM pipeline\n",
    "pipe1_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()), # with standardization StandardScaler()\n",
    "    ('PCA', PCA(n_components=200)), # 200 components to explain 95% of the variance (see first part of this notebook)\n",
    "    ('svc_linear', SVC(kernel='linear', random_state=0))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "# pipe1_svm.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the grid of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 6\n"
     ]
    }
   ],
   "source": [
    "# Grid of parameters\n",
    "grid1_svm = ParameterGrid({\n",
    "    'PCA__n_components':[200], # nb of components explaining 95% of the variance\n",
    "    'svc_linear__C':[0.01, 0.01, 0.1], # range of C defining the model complexity # [0.001,0.01,0.1]\n",
    "    'svc_linear__decision_function_shape':['ovo', 'ovr'] # testing 2 approaches as we have rather balanced # data points per class\n",
    "})\n",
    "\n",
    "# Print the number of combinations\n",
    "print('Number of combinations:', len(grid1_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model on on sub-train data set (5 000 tweets) and test accuracy on the validation data set (1 500 tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1/6\n",
      "Combination 2/6\n",
      "Combination 3/6\n",
      "Combination 4/6\n",
      "Combination 5/6\n",
      "Combination 6/6\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#  Save accuracy on train and validation sets\n",
    "train_scores=[]\n",
    "valid_scores = []\n",
    "\n",
    "# Enumerate combinations starting from 1\n",
    "for i, params_dict in enumerate(grid1_svm, 1):\n",
    "    # Print progress\n",
    "    print('Combination {}/{}'.format(\n",
    "        i, len(grid1_svm) # Total number of combinations\n",
    "    ))\n",
    "    \n",
    "    # Set parameters\n",
    "    pipe1_svm.set_params(**params_dict)\n",
    "\n",
    "    # Fit SVM\n",
    "    pipe1_svm.fit(X_tr_3rd, y_tr_3rd)\n",
    "\n",
    "    # Save accuracy on validation set   \n",
    "    params_dict['accuracy_train']= pipe1_svm.score(X_tr_3rd, y_tr_3rd)\n",
    "    params_dict['accuracy_valid'] = pipe1_svm.score(X_valid2, y_valid2)\n",
    "    \n",
    "    # Save result\n",
    "    train_scores.append(params_dict)\n",
    "    valid_scores.append(params_dict)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA__n_components</th>\n",
       "      <th>svc_linear__C</th>\n",
       "      <th>svc_linear__decision_function_shape</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.10</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.868667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.856667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.854667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.854667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.8746</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PCA__n_components  svc_linear__C svc_linear__decision_function_shape  \\\n",
       "5                200           0.10                                 ovr   \n",
       "4                200           0.10                                 ovo   \n",
       "2                200           0.01                                 ovo   \n",
       "1                200           0.01                                 ovr   \n",
       "3                200           0.01                                 ovr   \n",
       "0                200           0.01                                 ovo   \n",
       "\n",
       "   accuracy_train  accuracy_valid  \n",
       "5          0.8978        0.876667  \n",
       "4          0.9024        0.868667  \n",
       "2          0.8708        0.856667  \n",
       "1          0.8760        0.854667  \n",
       "3          0.8796        0.854667  \n",
       "0          0.8746        0.852000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(valid_scores)\n",
    "# Print scores\n",
    "scores_df.sort_values(by='accuracy_valid', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation confusion matrix on Top 2 models (based on accuracy): SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st model (Most accurate model #4 hyper-parameters; train dataset: 5 000, valid dataset: 1 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM pipeline\n",
    "pipe_svm1 = Pipeline([\n",
    "    ('scaler', StandardScaler()), # with standardization StandardScaler()\n",
    "    ('PCA', PCA(n_components=200)), # 200 components to explain 95% of the variance (see first part of this notebook)\n",
    "    ('SVM', SVC(kernel='linear', C = 0.1, decision_function_shape = 'ovo', random_state=0))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM\n",
    "model_svm1=pipe_svm1.fit(X_tr_3rd, y_tr_3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on X_valid dataset\n",
    "y_pred_svm1=pipe_svm1.predict(X_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.89      0.91      0.90       470\n",
      "     class 1       0.81      0.79      0.80       477\n",
      "     class 2       0.90      0.91      0.90       553\n",
      "\n",
      "    accuracy                           0.87      1500\n",
      "   macro avg       0.87      0.87      0.87      1500\n",
      "weighted avg       0.87      0.87      0.87      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusions report\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_valid2, y_pred_svm1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd model same as Model 1 (Most accurate model #4; train dataset: 60 000, valid dataset: 20 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM pipeline\n",
    "pipe_svm1 = Pipeline([\n",
    "    ('scaler', StandardScaler()), # with standardization StandardScaler()\n",
    "    ('PCA', PCA(n_components=200)), # 200 components to explain 95% of the variance (see first part of this notebook)\n",
    "    ('SVM', SVC(kernel='linear', C = 0.1, decision_function_shape = 'ovo', random_state=0))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM\n",
    "model_svm1=pipe_svm1.fit(X_tr_2nd, y_tr_2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on X_valid dataset\n",
    "y_pred_svm1=pipe_svm1.predict(X_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.95      0.96      0.96      6349\n",
      "     class 1       0.88      0.87      0.87      6512\n",
      "     class 2       0.92      0.92      0.92      7139\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.92      0.92      0.92     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusions report\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_valid1, y_pred_svm1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save SVM Liner Kernel model for further visualization and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'svm_Linear_acc' (float)\n",
      "Stored 'c1_svm_Linear_f1' (float)\n",
      "Stored 'c2_svm_Linear_f1' (float)\n",
      "Stored 'c3_svm_Linear_f1' (float)\n"
     ]
    }
   ],
   "source": [
    "svm_Linear_acc=0.90\n",
    "c1_svm_Linear_f1 = 0.93\n",
    "c2_svm_Linear_f1 = 0.85\n",
    "c3_svm_Linear_f1 = 0.93\n",
    "\n",
    "%store svm_Linear_acc\n",
    "%store c1_svm_Linear_f1\n",
    "%store c2_svm_Linear_f1\n",
    "%store c3_svm_Linear_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "> * The Best model candidate for SVM with Linear Kernel classifier is the **model 4**: SVM Linear Kernel, C = 0.1, decision function: ovo\n",
    "* There was a larger difference between the performances of the model trained on 5 000 and then on 60 000 tweets (respectively 0.86 vs 0.91) at the begii/nning of the modeling phse. This gap has been narrowing due to multiple iterations in order to tune the model. The accuracy is now the same and there is a slight improvement on the f1 scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create a SVM with RBF Kernel pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM pipeline\n",
    "pipe2_svm_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()), # with standardization StandardScaler()\n",
    "    ('PCA', PCA(n_components=200)), # 200 components to explain 95% of the variance\n",
    "    ('SVM_RBF', SVC(kernel='rbf', random_state=0))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('PCA',\n",
       "   PCA(copy=True, iterated_power='auto', n_components=200, random_state=None,\n",
       "       svd_solver='auto', tol=0.0, whiten=False)),\n",
       "  ('SVM_RBF', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "       kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "       shrinking=True, tol=0.001, verbose=False))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'PCA': PCA(copy=True, iterated_power='auto', n_components=200, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'SVM_RBF': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "     kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "     shrinking=True, tol=0.001, verbose=False),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'PCA__copy': True,\n",
       " 'PCA__iterated_power': 'auto',\n",
       " 'PCA__n_components': 200,\n",
       " 'PCA__random_state': None,\n",
       " 'PCA__svd_solver': 'auto',\n",
       " 'PCA__tol': 0.0,\n",
       " 'PCA__whiten': False,\n",
       " 'SVM_RBF__C': 1.0,\n",
       " 'SVM_RBF__cache_size': 200,\n",
       " 'SVM_RBF__class_weight': None,\n",
       " 'SVM_RBF__coef0': 0.0,\n",
       " 'SVM_RBF__decision_function_shape': 'ovr',\n",
       " 'SVM_RBF__degree': 3,\n",
       " 'SVM_RBF__gamma': 'auto_deprecated',\n",
       " 'SVM_RBF__kernel': 'rbf',\n",
       " 'SVM_RBF__max_iter': -1,\n",
       " 'SVM_RBF__probability': False,\n",
       " 'SVM_RBF__random_state': 0,\n",
       " 'SVM_RBF__shrinking': True,\n",
       " 'SVM_RBF__tol': 0.001,\n",
       " 'SVM_RBF__verbose': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get parameters\n",
    "pipe2_svm_rbf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the grid of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 12\n"
     ]
    }
   ],
   "source": [
    "# Grid of parameters\n",
    "grid2_svm_rbf = ParameterGrid({\n",
    "    'PCA__n_components':[200], # nb of components explaining 95% of the variance\n",
    "    'SVM_RBF__C':[10, 50], # range of C defining the model complexity\n",
    "    'SVM_RBF__gamma':[0.001, 0.0001,0.00001], # try lower than 0.001\n",
    "    'SVM_RBF__decision_function_shape':['ovr', 'ovo'], # OnevsRest (ovr)\n",
    "})\n",
    "\n",
    "# Print the number of combinations\n",
    "print('Number of combinations:', len(grid2_svm_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model on on sub-train data set (5 000 tweets) and test accuracy on the validation data set (1 500 tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1/12\n",
      "Combination 2/12\n",
      "Combination 3/12\n",
      "Combination 4/12\n",
      "Combination 5/12\n",
      "Combination 6/12\n",
      "Combination 7/12\n",
      "Combination 8/12\n",
      "Combination 9/12\n",
      "Combination 10/12\n",
      "Combination 11/12\n",
      "Combination 12/12\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#  Save accuracy on train and validation sets\n",
    "train_scores=[]\n",
    "valid_scores = []\n",
    "\n",
    "# Enumerate combinations starting from 1\n",
    "for i, params_dict in enumerate(grid2_svm_rbf, 1):\n",
    "    # Print progress\n",
    "    print('Combination {}/{}'.format(\n",
    "        i, len(grid2_svm_rbf) # Total number of combinations\n",
    "    ))\n",
    "    \n",
    "    # Set parameters\n",
    "    pipe2_svm_rbf.set_params(**params_dict)\n",
    "\n",
    "    # Fit a Decision Tree classifier\n",
    "    pipe2_svm_rbf.fit(X_tr_3rd, y_tr_3rd)\n",
    "\n",
    "    # Save accuracy on validation set   \n",
    "    params_dict['accuracy_train']= pipe2_svm_rbf.score(X_tr_3rd, y_tr_3rd)\n",
    "    params_dict['accuracy_valid'] = pipe2_svm_rbf.score(X_valid2, y_valid2)\n",
    "    \n",
    "    # Save result\n",
    "    train_scores.append(params_dict)\n",
    "    valid_scores.append(params_dict)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA__n_components</th>\n",
       "      <th>SVM_RBF__C</th>\n",
       "      <th>SVM_RBF__decision_function_shape</th>\n",
       "      <th>SVM_RBF__gamma</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>0.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.837333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.835333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.828667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.8290</td>\n",
       "      <td>0.827333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.822667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.821333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>0.774667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PCA__n_components  SVM_RBF__C SVM_RBF__decision_function_shape  \\\n",
       "10                200          50                              ovo   \n",
       "7                 200          50                              ovr   \n",
       "0                 200          10                              ovr   \n",
       "3                 200          10                              ovo   \n",
       "4                 200          10                              ovo   \n",
       "1                 200          10                              ovr   \n",
       "9                 200          50                              ovo   \n",
       "8                 200          50                              ovr   \n",
       "11                200          50                              ovo   \n",
       "6                 200          50                              ovr   \n",
       "2                 200          10                              ovr   \n",
       "5                 200          10                              ovo   \n",
       "\n",
       "    SVM_RBF__gamma  accuracy_train  accuracy_valid  \n",
       "10         0.00010          0.8882        0.854000  \n",
       "7          0.00010          0.8890        0.853333  \n",
       "0          0.00100          0.9610        0.842000  \n",
       "3          0.00100          0.9576        0.837333  \n",
       "4          0.00010          0.8518        0.835333  \n",
       "1          0.00010          0.8478        0.834000  \n",
       "9          0.00100          0.9934        0.828667  \n",
       "8          0.00001          0.8290        0.827333  \n",
       "11         0.00001          0.8320        0.822667  \n",
       "6          0.00100          0.9928        0.821333  \n",
       "2          0.00001          0.7778        0.776000  \n",
       "5          0.00001          0.7812        0.774667  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with test scores\n",
    "scores_df = pd.DataFrame(valid_scores)\n",
    "# Print scores\n",
    "scores_df.sort_values(by='accuracy_valid', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of confusion matrix on most accurate model: SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM pipeline\n",
    "pipe_svm_rbf1 = Pipeline([\n",
    "    ('scaler', StandardScaler()), # with standardization StandardScaler()\n",
    "    ('PCA', PCA(n_components=200)), # 200 components to explain 95% of the variance\n",
    "    ('SVM_RBF', SVC(kernel='rbf', C=50, decision_function_shape = 'ovo', gamma = 0.0001, random_state=0))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM\n",
    "model_svm_rbf1=pipe_svm_rbf1.fit(X_tr_3rd, y_tr_3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on X_valid dataset\n",
    "y_pred_svm_rbf1=pipe_svm_rbf1.predict(X_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.90      0.89      0.90       470\n",
      "     class 1       0.79      0.77      0.78       477\n",
      "     class 2       0.88      0.91      0.89       553\n",
      "\n",
      "    accuracy                           0.86      1500\n",
      "   macro avg       0.86      0.86      0.86      1500\n",
      "weighted avg       0.86      0.86      0.86      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusions report\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_valid2, y_pred_svm_rbf1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save SVM RBF Kernel model for further visualization and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'svm_rbf_acc' (float)\n",
      "Stored 'c1_svm_rbf_f1' (float)\n",
      "Stored 'c2_svm_rbf_f1' (float)\n",
      "Stored 'c3_svm_rbf_f1' (float)\n"
     ]
    }
   ],
   "source": [
    "svm_rbf_acc=0.85\n",
    "c1_svm_rbf_f1 = 0.89\n",
    "c2_svm_rbf_f1 = 0.77\n",
    "c3_svm_rbf_f1 = 0.88\n",
    "\n",
    "%store svm_rbf_acc\n",
    "%store c1_svm_rbf_f1\n",
    "%store c2_svm_rbf_f1\n",
    "%store c3_svm_rbf_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a cross-validation object with a grid of parameters for the SVC with RBF kernel\n",
    "> * Even if it does not seem that the SVM Model with RBF Kernel overfits train dataset, we could evaluate the performance of models using cross-validation with 5 folds (however, it will be more demanding in terms of computaional resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('PCA',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=200, random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('SVM_RBF',\n",
       "                                        SVC(C=50, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_funct...\n",
       "                                            max_iter=-1, probability=False,\n",
       "                                            random_state=0, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'PCA__n_components': [200], 'SVM_RBF__C': [10, 50],\n",
       "                          'SVM_RBF__decision_function_shape': ['ovr', 'ovo'],\n",
       "                          'SVM_RBF__gamma': [0.001, 0.0001, 1e-05]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create cross-validation object\n",
    "gridCV_svm_rbf = GridSearchCV(pipe2_svm_rbf, [{\n",
    "    'PCA__n_components':[200], # nb of components explaining 95% of the variance (previous run with 61 components; 80% explained has been tested)\n",
    "    'SVM_RBF__C':[10, 50], # range of C defining the model complexity (tested but not good: 1, 0.1)\n",
    "    'SVM_RBF__gamma':[0.001, 0.0001,0.00001],\n",
    "    'SVM_RBF__decision_function_shape':['ovr', 'ovo'], # OnevsOne (ovo), OnevsRest (ovr)\n",
    "}],cv=5)\n",
    "\n",
    "# Fit estimator\n",
    "gridCV_svm_rbf.fit(X_tr_3rd, y_tr_3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_PCA__n_components', 'param_SVM_RBF__C', 'param_SVM_RBF__decision_function_shape', 'param_SVM_RBF__gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the results with \"cv_results_\"\n",
    "gridCV_svm_rbf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA</th>\n",
       "      <th>C</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Decision</th>\n",
       "      <th>mean_te</th>\n",
       "      <th>std_te_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.018414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.010739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.016507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>0.019759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>0.011877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.019967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.013153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.017941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.016314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.017551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.022143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.7418</td>\n",
       "      <td>0.021117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PCA   C   Gamma Decision  mean_te  std_te_score\n",
       "10  200  50  0.0001      ovo   0.8260      0.018414\n",
       "7   200  50  0.0001      ovr   0.8228      0.010739\n",
       "3   200  10   0.001      ovo   0.8160      0.016507\n",
       "0   200  10   0.001      ovr   0.8148      0.019759\n",
       "9   200  50   0.001      ovo   0.8068      0.011877\n",
       "6   200  50   0.001      ovr   0.8030      0.019967\n",
       "1   200  10  0.0001      ovr   0.7996      0.013153\n",
       "4   200  10  0.0001      ovo   0.7964      0.017941\n",
       "11  200  50   1e-05      ovo   0.7874      0.016314\n",
       "8   200  50   1e-05      ovr   0.7862      0.017551\n",
       "2   200  10   1e-05      ovr   0.7438      0.022143\n",
       "5   200  10   1e-05      ovo   0.7418      0.021117"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect results in a DataFrame\n",
    "df_svc_linear = pd.DataFrame.from_items([\n",
    "    ('PCA', gridCV_svm_rbf.cv_results_['param_PCA__n_components']),\n",
    "    ('C', gridCV_svm_rbf.cv_results_['param_SVM_RBF__C']),\n",
    "    ('Gamma', gridCV_svm_rbf.cv_results_['param_SVM_RBF__gamma']),\n",
    "    ('Decision', gridCV_svm_rbf.cv_results_['param_SVM_RBF__decision_function_shape']),\n",
    "    ('mean_te', gridCV_svm_rbf.cv_results_['mean_test_score']),\n",
    "    ('std_te_score', gridCV_svm_rbf.cv_results_['std_test_score']),\n",
    "    \n",
    "])\n",
    "df_svc_linear.sort_values(by='mean_te', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusions on SVM RBF with cross-validation\n",
    "> * It is not really conclusive as the 2nd best model (with an equivalent set of hyper-parameter tuning) is performing less (accuracy on test 0.8262) than the same one with the standard train/valid dataset (acc. 0.85); original evaluation prior to multiple iterations for tuning the original model.\n",
    "* As a consequence, we will select the standard approach which provides slightly better results and being less computing resource demanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
